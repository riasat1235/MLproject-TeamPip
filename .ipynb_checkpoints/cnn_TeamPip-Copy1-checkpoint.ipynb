{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook aims at discovering Convolutional Neural Network. We will see the theory behind it, and an implementation in Pytorch for hand-digits classification on MNIST dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "source": [
    "# History\n",
    "\n",
    "Contrary to what most people think, Neural Networks is quite an old concept. It was first introduced in 1957 under the name ***perceptron***. Peceptron is a 1-layer feed forward neural network. However the infrastructure and the algorthm around it was not good enough to allow large scale training. Later on in 1986, ***Multi Layer Perceptron (MLP)*** was introduced with the backpropagation algorithm in order to train a network with more than 1 layer. Thanks to this algorithm we are not able to train non-linear model which can learn high level abstract features. Then ***Convolutional Neural Network (CNN)*** has been introduced in order to learn better features and with the possibility to reduce the number of parameters to be trained. And now, here we are, in the ***Deep Learning era*** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b3124a67ef42274e81ddbd3d46d4937a3e2dfaa5"
   },
   "source": [
    "    # Multi-Layer Perceptron\n",
    "\n",
    "The first thing to ask is : why do we needed Convolutional Neural Network in the first place... Well, let's see what happen when we train a Multi-Layer Perceptron to recognize hand-written digits. In Machine Learning we have our own \"Hello World\" which is the MNIST dataset. Let's see what this dataset is about and how a multi-layer perceptron will perform.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "46ade2a1807aadd90e577c496d77d3df507dad88"
   },
   "outputs": [],
   "source": [
    "import numpy as np # to handle matrix and data operation\n",
    "import pandas as pd # to read csv and handle dataframe\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "a87c9de979fb54874e3a047d40cc024a8b0f5e98"
   },
   "outputs": [],
   "source": [
    "data = np.load('Data/data_train.npy').T\n",
    "X_og = data.copy()/255\n",
    "y_og =np.load('Data/labels_corrected.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.63137255 0.63529412 0.63529412 ... 0.58431373 0.58431373 0.57647059]\n",
      " [0.63529412 0.63529412 0.63529412 ... 0.64705882 0.64705882 0.64705882]\n",
      " [0.76470588 0.76470588 0.76470588 ... 0.74901961 0.74901961 0.74901961]\n",
      " ...\n",
      " [0.76470588 0.76470588 0.76470588 ... 0.76470588 0.76470588 0.76470588]\n",
      " [0.61960784 0.61568627 0.61568627 ... 0.55294118 0.54901961 0.55294118]\n",
      " [0.58431373 0.58431373 0.58823529 ... 0.54117647 0.55686275 0.57647059]]\n"
     ]
    }
   ],
   "source": [
    "print(X_og)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 8 1 ... 1 3 3]\n"
     ]
    }
   ],
   "source": [
    "y = y_og.astype(int)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6720, 90000)\n",
      "(6720,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_og))\n",
    "print(np.shape(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = 1-X_og.copy()\n",
    "def resize_func(input_data,new_width,new_height):#input the (1,90000) data\n",
    "    size1 = np.shape(input_data)[0]\n",
    "    size2 = int(size1**(0.5))\n",
    "    output = cv2.resize(input_data.reshape(size2,size2),(new_width,new_height))\n",
    "    return output\n",
    "\n",
    "\n",
    "def morph_ops(input_data,n_width,n_height): # morphological operations \n",
    "    dilate_kernel = np.ones((2,2),np.uint8)\n",
    "    x0 = 1-input_data\n",
    "    x0_1 = resize_func(x0,n_width,n_height)\n",
    "    x1 = x0_1.reshape(n_width,n_height)\n",
    "    x4 = np.clip(x1-np.mean(x1),0,1)\n",
    "    x5 = np.where(x1 < 0.35,0,x4)\n",
    "    dilate_kernel = np.ones((2,2),np.uint8)\n",
    "    x6 = cv2.dilate(x5,dilate_kernel,iterations=1)\n",
    "    x7 = np.where(x6<0.15,0,x6)\n",
    "    x8 = normalize(x7.reshape(-1,1)).reshape(n_width,n_height)\n",
    "    x9 = np.where(x8>0.3,1,x8)\n",
    "    x10 = x9.reshape(1,-1)\n",
    "    picture = x10\n",
    "    return picture # 1, n_width*n_height\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##parameters \n",
    "# size after resize the original image \n",
    "n_width  =50 \n",
    "n_height =50\n",
    "\n",
    "# split data\n",
    "test_data_size=0.2\n",
    "\n",
    "#batch and Epoch \n",
    "BATCH SIZE =200\n",
    "Epoch = 250 \n",
    "\n",
    "\n",
    "# number of hidden layers \n",
    "h_layer_1 = 500 # hidden layer 1\n",
    "h_layer_2 = 100 # hidden layer 2\n",
    "h_layer_3 = 10  # hidden layer 3\n",
    "\n",
    "# learning rate \n",
    "lr = 0.001\n",
    "\n",
    "# cnn kernel size \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = np.zeros((np.shape(X_og)[0],50*50))\n",
    "\n",
    "for ii in range(np.shape(X_new)[0]):\n",
    "    newrow = morph_ops(X_og[ii,:])\n",
    "    newrow = newrow.reshape(1,-1)\n",
    "    newrow = resize_func(newrow[0,:],50,50)\n",
    "    newrow = newrow.reshape(1,-1)\n",
    "    X_new[ii,:] = newrow\n",
    "X = X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2544f82e520>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 0\n",
    "x1 = X[index,:].reshape(50,50)\n",
    "plt.imshow(x1,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "_uuid": "0b3d551a62defaadd37e681511ebc5fc70ac944d"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "_uuid": "96f0d5dbc90457eb091fb2e6ed68ce7c7bf6da0b"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 200\n",
    "\n",
    "torch_X_train = torch.from_numpy(X_train).type(torch.LongTensor)\n",
    "torch_y_train = torch.from_numpy(y_train).type(torch.LongTensor) # data type is long\n",
    "\n",
    "# create feature and targets tensor for test set.\n",
    "torch_X_test = torch.from_numpy(X_test).type(torch.LongTensor)\n",
    "torch_y_test = torch.from_numpy(y_test).type(torch.LongTensor) # data type is long\n",
    "\n",
    "# Pytorch train and test sets\n",
    "train = torch.utils.data.TensorDataset(torch_X_train,torch_y_train)\n",
    "test = torch.utils.data.TensorDataset(torch_X_test,torch_y_test)\n",
    "\n",
    "# data loader\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size = BATCH_SIZE, shuffle = False)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size = BATCH_SIZE, shuffle = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "_uuid": "3624b779d746e6b5710711c7b1798363ecabafbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (linear1): Linear(in_features=2500, out_features=500, bias=True)\n",
      "  (linear2): Linear(in_features=500, out_features=100, bias=True)\n",
      "  (linear3): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.linear1 = nn.Linear(50*50,500)\n",
    "        self.linear2 = nn.Linear(500,100)\n",
    "        self.linear3 = nn.Linear(100,10)\n",
    "    \n",
    "    def forward(self,X):\n",
    "        X = F.relu(self.linear1(X))\n",
    "        X = F.relu(self.linear2(X))\n",
    "        X = self.linear3(X)\n",
    "        return F.log_softmax(X, dim=1)\n",
    " \n",
    "mlp = MLP()\n",
    "print(mlp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6c2c74a49c925222b6aaec5e29007a302d2fae44"
   },
   "source": [
    "We have 784\\*(250+1) + 250\\*(100+1) + 100\\*(10+1) = 222 360 parameters to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "_uuid": "e471e447a9618edc7310bb15941054c30ea235a4"
   },
   "outputs": [],
   "source": [
    "def fit(model, train_loader):\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=1e-3)#,lr=0.001, betas=(0.9,0.999))\n",
    "    error = nn.CrossEntropyLoss()\n",
    "    EPOCHS = 250\n",
    "    model.train()\n",
    "    lossvec = []\n",
    "    for epoch in range(EPOCHS):\n",
    "        correct = 0\n",
    "        for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n",
    "            var_X_batch = Variable(X_batch).float()\n",
    "            var_y_batch = Variable(y_batch)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(var_X_batch)\n",
    "            loss = error(output, var_y_batch)\n",
    "            loss.backward()\n",
    "            lossvec.append(loss.item())\n",
    "            optimizer.step()\n",
    "\n",
    "            # Total correct predictions\n",
    "            #predicted = torch.max(output.data,0)[1]\n",
    "            predicted = torch.max(output.data, 1)[1] \n",
    "            correct += (predicted == var_y_batch).sum()\n",
    "            #print(correct)\n",
    "            if batch_idx % 100 == 0:\n",
    "                print('Epoch : {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\t Accuracy:{:.3f}%'.format(\n",
    "                    epoch, batch_idx*len(X_batch), len(train_loader.dataset), 100.*batch_idx / len(train_loader), loss.item(), float(correct*100) / float(BATCH_SIZE*(batch_idx+1))))\n",
    "    return lossvec\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "_uuid": "766f99fea9d2295443131e64e9bda28e1ea1efe5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 [0/5376 (0%)]\tLoss: 2.308540\t Accuracy:11.500%\n",
      "Epoch : 1 [0/5376 (0%)]\tLoss: 1.550054\t Accuracy:50.000%\n",
      "Epoch : 2 [0/5376 (0%)]\tLoss: 1.245156\t Accuracy:61.500%\n",
      "Epoch : 3 [0/5376 (0%)]\tLoss: 0.990328\t Accuracy:71.000%\n",
      "Epoch : 4 [0/5376 (0%)]\tLoss: 0.767749\t Accuracy:78.000%\n",
      "Epoch : 5 [0/5376 (0%)]\tLoss: 0.575144\t Accuracy:85.000%\n",
      "Epoch : 6 [0/5376 (0%)]\tLoss: 0.471227\t Accuracy:86.500%\n",
      "Epoch : 7 [0/5376 (0%)]\tLoss: 0.328446\t Accuracy:90.000%\n",
      "Epoch : 8 [0/5376 (0%)]\tLoss: 0.271350\t Accuracy:94.500%\n",
      "Epoch : 9 [0/5376 (0%)]\tLoss: 0.191229\t Accuracy:96.000%\n",
      "Epoch : 10 [0/5376 (0%)]\tLoss: 0.179959\t Accuracy:95.000%\n",
      "Epoch : 11 [0/5376 (0%)]\tLoss: 0.115611\t Accuracy:97.500%\n",
      "Epoch : 12 [0/5376 (0%)]\tLoss: 0.114002\t Accuracy:97.000%\n",
      "Epoch : 13 [0/5376 (0%)]\tLoss: 0.060140\t Accuracy:99.000%\n",
      "Epoch : 14 [0/5376 (0%)]\tLoss: 0.094482\t Accuracy:98.000%\n",
      "Epoch : 15 [0/5376 (0%)]\tLoss: 0.061409\t Accuracy:99.500%\n",
      "Epoch : 16 [0/5376 (0%)]\tLoss: 0.078319\t Accuracy:98.500%\n",
      "Epoch : 17 [0/5376 (0%)]\tLoss: 0.039126\t Accuracy:99.500%\n",
      "Epoch : 18 [0/5376 (0%)]\tLoss: 0.019651\t Accuracy:100.000%\n",
      "Epoch : 19 [0/5376 (0%)]\tLoss: 0.021344\t Accuracy:99.500%\n",
      "Epoch : 20 [0/5376 (0%)]\tLoss: 0.020439\t Accuracy:100.000%\n",
      "Epoch : 21 [0/5376 (0%)]\tLoss: 0.012718\t Accuracy:100.000%\n",
      "Epoch : 22 [0/5376 (0%)]\tLoss: 0.010292\t Accuracy:100.000%\n",
      "Epoch : 23 [0/5376 (0%)]\tLoss: 0.008644\t Accuracy:100.000%\n",
      "Epoch : 24 [0/5376 (0%)]\tLoss: 0.007791\t Accuracy:100.000%\n",
      "Epoch : 25 [0/5376 (0%)]\tLoss: 0.010800\t Accuracy:99.500%\n",
      "Epoch : 26 [0/5376 (0%)]\tLoss: 0.005847\t Accuracy:100.000%\n",
      "Epoch : 27 [0/5376 (0%)]\tLoss: 0.004963\t Accuracy:100.000%\n",
      "Epoch : 28 [0/5376 (0%)]\tLoss: 0.004706\t Accuracy:100.000%\n",
      "Epoch : 29 [0/5376 (0%)]\tLoss: 0.004237\t Accuracy:100.000%\n",
      "Epoch : 30 [0/5376 (0%)]\tLoss: 0.003751\t Accuracy:100.000%\n",
      "Epoch : 31 [0/5376 (0%)]\tLoss: 0.003731\t Accuracy:100.000%\n",
      "Epoch : 32 [0/5376 (0%)]\tLoss: 0.003740\t Accuracy:100.000%\n",
      "Epoch : 33 [0/5376 (0%)]\tLoss: 0.003527\t Accuracy:100.000%\n",
      "Epoch : 34 [0/5376 (0%)]\tLoss: 0.003051\t Accuracy:100.000%\n",
      "Epoch : 35 [0/5376 (0%)]\tLoss: 0.002641\t Accuracy:100.000%\n",
      "Epoch : 36 [0/5376 (0%)]\tLoss: 0.002296\t Accuracy:100.000%\n",
      "Epoch : 37 [0/5376 (0%)]\tLoss: 0.002025\t Accuracy:100.000%\n",
      "Epoch : 38 [0/5376 (0%)]\tLoss: 0.001839\t Accuracy:100.000%\n",
      "Epoch : 39 [0/5376 (0%)]\tLoss: 0.001698\t Accuracy:100.000%\n",
      "Epoch : 40 [0/5376 (0%)]\tLoss: 0.001598\t Accuracy:100.000%\n",
      "Epoch : 41 [0/5376 (0%)]\tLoss: 0.001507\t Accuracy:100.000%\n",
      "Epoch : 42 [0/5376 (0%)]\tLoss: 0.001431\t Accuracy:100.000%\n",
      "Epoch : 43 [0/5376 (0%)]\tLoss: 0.001355\t Accuracy:100.000%\n",
      "Epoch : 44 [0/5376 (0%)]\tLoss: 0.001292\t Accuracy:100.000%\n",
      "Epoch : 45 [0/5376 (0%)]\tLoss: 0.001226\t Accuracy:100.000%\n",
      "Epoch : 46 [0/5376 (0%)]\tLoss: 0.001168\t Accuracy:100.000%\n",
      "Epoch : 47 [0/5376 (0%)]\tLoss: 0.001114\t Accuracy:100.000%\n",
      "Epoch : 48 [0/5376 (0%)]\tLoss: 0.001064\t Accuracy:100.000%\n",
      "Epoch : 49 [0/5376 (0%)]\tLoss: 0.001013\t Accuracy:100.000%\n",
      "Epoch : 50 [0/5376 (0%)]\tLoss: 0.000971\t Accuracy:100.000%\n",
      "Epoch : 51 [0/5376 (0%)]\tLoss: 0.000929\t Accuracy:100.000%\n",
      "Epoch : 52 [0/5376 (0%)]\tLoss: 0.000890\t Accuracy:100.000%\n",
      "Epoch : 53 [0/5376 (0%)]\tLoss: 0.000850\t Accuracy:100.000%\n",
      "Epoch : 54 [0/5376 (0%)]\tLoss: 0.000815\t Accuracy:100.000%\n",
      "Epoch : 55 [0/5376 (0%)]\tLoss: 0.000781\t Accuracy:100.000%\n",
      "Epoch : 56 [0/5376 (0%)]\tLoss: 0.000751\t Accuracy:100.000%\n",
      "Epoch : 57 [0/5376 (0%)]\tLoss: 0.000718\t Accuracy:100.000%\n",
      "Epoch : 58 [0/5376 (0%)]\tLoss: 0.000692\t Accuracy:100.000%\n",
      "Epoch : 59 [0/5376 (0%)]\tLoss: 0.000665\t Accuracy:100.000%\n",
      "Epoch : 60 [0/5376 (0%)]\tLoss: 0.000639\t Accuracy:100.000%\n",
      "Epoch : 61 [0/5376 (0%)]\tLoss: 0.000616\t Accuracy:100.000%\n",
      "Epoch : 62 [0/5376 (0%)]\tLoss: 0.000592\t Accuracy:100.000%\n",
      "Epoch : 63 [0/5376 (0%)]\tLoss: 0.000570\t Accuracy:100.000%\n",
      "Epoch : 64 [0/5376 (0%)]\tLoss: 0.000551\t Accuracy:100.000%\n",
      "Epoch : 65 [0/5376 (0%)]\tLoss: 0.000530\t Accuracy:100.000%\n",
      "Epoch : 66 [0/5376 (0%)]\tLoss: 0.000512\t Accuracy:100.000%\n",
      "Epoch : 67 [0/5376 (0%)]\tLoss: 0.000494\t Accuracy:100.000%\n",
      "Epoch : 68 [0/5376 (0%)]\tLoss: 0.000477\t Accuracy:100.000%\n",
      "Epoch : 69 [0/5376 (0%)]\tLoss: 0.000461\t Accuracy:100.000%\n",
      "Epoch : 70 [0/5376 (0%)]\tLoss: 0.000446\t Accuracy:100.000%\n",
      "Epoch : 71 [0/5376 (0%)]\tLoss: 0.000431\t Accuracy:100.000%\n",
      "Epoch : 72 [0/5376 (0%)]\tLoss: 0.000417\t Accuracy:100.000%\n",
      "Epoch : 73 [0/5376 (0%)]\tLoss: 0.000404\t Accuracy:100.000%\n",
      "Epoch : 74 [0/5376 (0%)]\tLoss: 0.000391\t Accuracy:100.000%\n",
      "Epoch : 75 [0/5376 (0%)]\tLoss: 0.000378\t Accuracy:100.000%\n",
      "Epoch : 76 [0/5376 (0%)]\tLoss: 0.000367\t Accuracy:100.000%\n",
      "Epoch : 77 [0/5376 (0%)]\tLoss: 0.000355\t Accuracy:100.000%\n",
      "Epoch : 78 [0/5376 (0%)]\tLoss: 0.000345\t Accuracy:100.000%\n",
      "Epoch : 79 [0/5376 (0%)]\tLoss: 0.000334\t Accuracy:100.000%\n",
      "Epoch : 80 [0/5376 (0%)]\tLoss: 0.000324\t Accuracy:100.000%\n",
      "Epoch : 81 [0/5376 (0%)]\tLoss: 0.000314\t Accuracy:100.000%\n",
      "Epoch : 82 [0/5376 (0%)]\tLoss: 0.000305\t Accuracy:100.000%\n",
      "Epoch : 83 [0/5376 (0%)]\tLoss: 0.000296\t Accuracy:100.000%\n",
      "Epoch : 84 [0/5376 (0%)]\tLoss: 0.000288\t Accuracy:100.000%\n",
      "Epoch : 85 [0/5376 (0%)]\tLoss: 0.000280\t Accuracy:100.000%\n",
      "Epoch : 86 [0/5376 (0%)]\tLoss: 0.000272\t Accuracy:100.000%\n",
      "Epoch : 87 [0/5376 (0%)]\tLoss: 0.000264\t Accuracy:100.000%\n",
      "Epoch : 88 [0/5376 (0%)]\tLoss: 0.000257\t Accuracy:100.000%\n",
      "Epoch : 89 [0/5376 (0%)]\tLoss: 0.000249\t Accuracy:100.000%\n",
      "Epoch : 90 [0/5376 (0%)]\tLoss: 0.000243\t Accuracy:100.000%\n",
      "Epoch : 91 [0/5376 (0%)]\tLoss: 0.000236\t Accuracy:100.000%\n",
      "Epoch : 92 [0/5376 (0%)]\tLoss: 0.000230\t Accuracy:100.000%\n",
      "Epoch : 93 [0/5376 (0%)]\tLoss: 0.000223\t Accuracy:100.000%\n",
      "Epoch : 94 [0/5376 (0%)]\tLoss: 0.000217\t Accuracy:100.000%\n",
      "Epoch : 95 [0/5376 (0%)]\tLoss: 0.000212\t Accuracy:100.000%\n",
      "Epoch : 96 [0/5376 (0%)]\tLoss: 0.000206\t Accuracy:100.000%\n",
      "Epoch : 97 [0/5376 (0%)]\tLoss: 0.000201\t Accuracy:100.000%\n",
      "Epoch : 98 [0/5376 (0%)]\tLoss: 0.000196\t Accuracy:100.000%\n",
      "Epoch : 99 [0/5376 (0%)]\tLoss: 0.000191\t Accuracy:100.000%\n",
      "Epoch : 100 [0/5376 (0%)]\tLoss: 0.000186\t Accuracy:100.000%\n",
      "Epoch : 101 [0/5376 (0%)]\tLoss: 0.000181\t Accuracy:100.000%\n",
      "Epoch : 102 [0/5376 (0%)]\tLoss: 0.000177\t Accuracy:100.000%\n",
      "Epoch : 103 [0/5376 (0%)]\tLoss: 0.000172\t Accuracy:100.000%\n",
      "Epoch : 104 [0/5376 (0%)]\tLoss: 0.000168\t Accuracy:100.000%\n",
      "Epoch : 105 [0/5376 (0%)]\tLoss: 0.000164\t Accuracy:100.000%\n",
      "Epoch : 106 [0/5376 (0%)]\tLoss: 0.000160\t Accuracy:100.000%\n",
      "Epoch : 107 [0/5376 (0%)]\tLoss: 0.000156\t Accuracy:100.000%\n",
      "Epoch : 108 [0/5376 (0%)]\tLoss: 0.000153\t Accuracy:100.000%\n",
      "Epoch : 109 [0/5376 (0%)]\tLoss: 0.000149\t Accuracy:100.000%\n",
      "Epoch : 110 [0/5376 (0%)]\tLoss: 0.000145\t Accuracy:100.000%\n",
      "Epoch : 111 [0/5376 (0%)]\tLoss: 0.000142\t Accuracy:100.000%\n",
      "Epoch : 112 [0/5376 (0%)]\tLoss: 0.000139\t Accuracy:100.000%\n",
      "Epoch : 113 [0/5376 (0%)]\tLoss: 0.000135\t Accuracy:100.000%\n",
      "Epoch : 114 [0/5376 (0%)]\tLoss: 0.000132\t Accuracy:100.000%\n",
      "Epoch : 115 [0/5376 (0%)]\tLoss: 0.000129\t Accuracy:100.000%\n",
      "Epoch : 116 [0/5376 (0%)]\tLoss: 0.000126\t Accuracy:100.000%\n",
      "Epoch : 117 [0/5376 (0%)]\tLoss: 0.000123\t Accuracy:100.000%\n",
      "Epoch : 118 [0/5376 (0%)]\tLoss: 0.000121\t Accuracy:100.000%\n",
      "Epoch : 119 [0/5376 (0%)]\tLoss: 0.000118\t Accuracy:100.000%\n",
      "Epoch : 120 [0/5376 (0%)]\tLoss: 0.000115\t Accuracy:100.000%\n",
      "Epoch : 121 [0/5376 (0%)]\tLoss: 0.000113\t Accuracy:100.000%\n",
      "Epoch : 122 [0/5376 (0%)]\tLoss: 0.000110\t Accuracy:100.000%\n",
      "Epoch : 123 [0/5376 (0%)]\tLoss: 0.000108\t Accuracy:100.000%\n",
      "Epoch : 124 [0/5376 (0%)]\tLoss: 0.000105\t Accuracy:100.000%\n",
      "Epoch : 125 [0/5376 (0%)]\tLoss: 0.000103\t Accuracy:100.000%\n",
      "Epoch : 126 [0/5376 (0%)]\tLoss: 0.000101\t Accuracy:100.000%\n",
      "Epoch : 127 [0/5376 (0%)]\tLoss: 0.000099\t Accuracy:100.000%\n",
      "Epoch : 128 [0/5376 (0%)]\tLoss: 0.000097\t Accuracy:100.000%\n",
      "Epoch : 129 [0/5376 (0%)]\tLoss: 0.000095\t Accuracy:100.000%\n",
      "Epoch : 130 [0/5376 (0%)]\tLoss: 0.000093\t Accuracy:100.000%\n",
      "Epoch : 131 [0/5376 (0%)]\tLoss: 0.000091\t Accuracy:100.000%\n",
      "Epoch : 132 [0/5376 (0%)]\tLoss: 0.000089\t Accuracy:100.000%\n",
      "Epoch : 133 [0/5376 (0%)]\tLoss: 0.000087\t Accuracy:100.000%\n",
      "Epoch : 134 [0/5376 (0%)]\tLoss: 0.000085\t Accuracy:100.000%\n",
      "Epoch : 135 [0/5376 (0%)]\tLoss: 0.000083\t Accuracy:100.000%\n",
      "Epoch : 136 [0/5376 (0%)]\tLoss: 0.000081\t Accuracy:100.000%\n",
      "Epoch : 137 [0/5376 (0%)]\tLoss: 0.000080\t Accuracy:100.000%\n",
      "Epoch : 138 [0/5376 (0%)]\tLoss: 0.000078\t Accuracy:100.000%\n",
      "Epoch : 139 [0/5376 (0%)]\tLoss: 0.000077\t Accuracy:100.000%\n",
      "Epoch : 140 [0/5376 (0%)]\tLoss: 0.000075\t Accuracy:100.000%\n",
      "Epoch : 141 [0/5376 (0%)]\tLoss: 0.000074\t Accuracy:100.000%\n",
      "Epoch : 142 [0/5376 (0%)]\tLoss: 0.000072\t Accuracy:100.000%\n",
      "Epoch : 143 [0/5376 (0%)]\tLoss: 0.000071\t Accuracy:100.000%\n",
      "Epoch : 144 [0/5376 (0%)]\tLoss: 0.000069\t Accuracy:100.000%\n",
      "Epoch : 145 [0/5376 (0%)]\tLoss: 0.000068\t Accuracy:100.000%\n",
      "Epoch : 146 [0/5376 (0%)]\tLoss: 0.000066\t Accuracy:100.000%\n",
      "Epoch : 147 [0/5376 (0%)]\tLoss: 0.000065\t Accuracy:100.000%\n",
      "Epoch : 148 [0/5376 (0%)]\tLoss: 0.000064\t Accuracy:100.000%\n",
      "Epoch : 149 [0/5376 (0%)]\tLoss: 0.000063\t Accuracy:100.000%\n",
      "Epoch : 150 [0/5376 (0%)]\tLoss: 0.000061\t Accuracy:100.000%\n",
      "Epoch : 151 [0/5376 (0%)]\tLoss: 0.000060\t Accuracy:100.000%\n",
      "Epoch : 152 [0/5376 (0%)]\tLoss: 0.000059\t Accuracy:100.000%\n",
      "Epoch : 153 [0/5376 (0%)]\tLoss: 0.000058\t Accuracy:100.000%\n",
      "Epoch : 154 [0/5376 (0%)]\tLoss: 0.000057\t Accuracy:100.000%\n",
      "Epoch : 155 [0/5376 (0%)]\tLoss: 0.000056\t Accuracy:100.000%\n",
      "Epoch : 156 [0/5376 (0%)]\tLoss: 0.000054\t Accuracy:100.000%\n",
      "Epoch : 157 [0/5376 (0%)]\tLoss: 0.000053\t Accuracy:100.000%\n",
      "Epoch : 158 [0/5376 (0%)]\tLoss: 0.000052\t Accuracy:100.000%\n",
      "Epoch : 159 [0/5376 (0%)]\tLoss: 0.000051\t Accuracy:100.000%\n",
      "Epoch : 160 [0/5376 (0%)]\tLoss: 0.000050\t Accuracy:100.000%\n",
      "Epoch : 161 [0/5376 (0%)]\tLoss: 0.000049\t Accuracy:100.000%\n",
      "Epoch : 162 [0/5376 (0%)]\tLoss: 0.000048\t Accuracy:100.000%\n",
      "Epoch : 163 [0/5376 (0%)]\tLoss: 0.000048\t Accuracy:100.000%\n",
      "Epoch : 164 [0/5376 (0%)]\tLoss: 0.000047\t Accuracy:100.000%\n",
      "Epoch : 165 [0/5376 (0%)]\tLoss: 0.000046\t Accuracy:100.000%\n",
      "Epoch : 166 [0/5376 (0%)]\tLoss: 0.000045\t Accuracy:100.000%\n",
      "Epoch : 167 [0/5376 (0%)]\tLoss: 0.000044\t Accuracy:100.000%\n",
      "Epoch : 168 [0/5376 (0%)]\tLoss: 0.000043\t Accuracy:100.000%\n",
      "Epoch : 169 [0/5376 (0%)]\tLoss: 0.000042\t Accuracy:100.000%\n",
      "Epoch : 170 [0/5376 (0%)]\tLoss: 0.000042\t Accuracy:100.000%\n",
      "Epoch : 171 [0/5376 (0%)]\tLoss: 0.000041\t Accuracy:100.000%\n",
      "Epoch : 172 [0/5376 (0%)]\tLoss: 0.000040\t Accuracy:100.000%\n",
      "Epoch : 173 [0/5376 (0%)]\tLoss: 0.000039\t Accuracy:100.000%\n",
      "Epoch : 174 [0/5376 (0%)]\tLoss: 0.000039\t Accuracy:100.000%\n",
      "Epoch : 175 [0/5376 (0%)]\tLoss: 0.000038\t Accuracy:100.000%\n",
      "Epoch : 176 [0/5376 (0%)]\tLoss: 0.000037\t Accuracy:100.000%\n",
      "Epoch : 177 [0/5376 (0%)]\tLoss: 0.000036\t Accuracy:100.000%\n",
      "Epoch : 178 [0/5376 (0%)]\tLoss: 0.000036\t Accuracy:100.000%\n",
      "Epoch : 179 [0/5376 (0%)]\tLoss: 0.000035\t Accuracy:100.000%\n",
      "Epoch : 180 [0/5376 (0%)]\tLoss: 0.000034\t Accuracy:100.000%\n",
      "Epoch : 181 [0/5376 (0%)]\tLoss: 0.000034\t Accuracy:100.000%\n",
      "Epoch : 182 [0/5376 (0%)]\tLoss: 0.000033\t Accuracy:100.000%\n",
      "Epoch : 183 [0/5376 (0%)]\tLoss: 0.000033\t Accuracy:100.000%\n",
      "Epoch : 184 [0/5376 (0%)]\tLoss: 0.000032\t Accuracy:100.000%\n",
      "Epoch : 185 [0/5376 (0%)]\tLoss: 0.000031\t Accuracy:100.000%\n",
      "Epoch : 186 [0/5376 (0%)]\tLoss: 0.000031\t Accuracy:100.000%\n",
      "Epoch : 187 [0/5376 (0%)]\tLoss: 0.000030\t Accuracy:100.000%\n",
      "Epoch : 188 [0/5376 (0%)]\tLoss: 0.000030\t Accuracy:100.000%\n",
      "Epoch : 189 [0/5376 (0%)]\tLoss: 0.000029\t Accuracy:100.000%\n",
      "Epoch : 190 [0/5376 (0%)]\tLoss: 0.000029\t Accuracy:100.000%\n",
      "Epoch : 191 [0/5376 (0%)]\tLoss: 0.000028\t Accuracy:100.000%\n",
      "Epoch : 192 [0/5376 (0%)]\tLoss: 0.000028\t Accuracy:100.000%\n",
      "Epoch : 193 [0/5376 (0%)]\tLoss: 0.000027\t Accuracy:100.000%\n",
      "Epoch : 194 [0/5376 (0%)]\tLoss: 0.000027\t Accuracy:100.000%\n",
      "Epoch : 195 [0/5376 (0%)]\tLoss: 0.000026\t Accuracy:100.000%\n",
      "Epoch : 196 [0/5376 (0%)]\tLoss: 0.000026\t Accuracy:100.000%\n",
      "Epoch : 197 [0/5376 (0%)]\tLoss: 0.000025\t Accuracy:100.000%\n",
      "Epoch : 198 [0/5376 (0%)]\tLoss: 0.000025\t Accuracy:100.000%\n",
      "Epoch : 199 [0/5376 (0%)]\tLoss: 0.000024\t Accuracy:100.000%\n",
      "Epoch : 200 [0/5376 (0%)]\tLoss: 0.000024\t Accuracy:100.000%\n",
      "Epoch : 201 [0/5376 (0%)]\tLoss: 0.000024\t Accuracy:100.000%\n",
      "Epoch : 202 [0/5376 (0%)]\tLoss: 0.000023\t Accuracy:100.000%\n",
      "Epoch : 203 [0/5376 (0%)]\tLoss: 0.000023\t Accuracy:100.000%\n",
      "Epoch : 204 [0/5376 (0%)]\tLoss: 0.000022\t Accuracy:100.000%\n",
      "Epoch : 205 [0/5376 (0%)]\tLoss: 0.000022\t Accuracy:100.000%\n",
      "Epoch : 206 [0/5376 (0%)]\tLoss: 0.000022\t Accuracy:100.000%\n",
      "Epoch : 207 [0/5376 (0%)]\tLoss: 0.000021\t Accuracy:100.000%\n",
      "Epoch : 208 [0/5376 (0%)]\tLoss: 0.000021\t Accuracy:100.000%\n",
      "Epoch : 209 [0/5376 (0%)]\tLoss: 0.000020\t Accuracy:100.000%\n",
      "Epoch : 210 [0/5376 (0%)]\tLoss: 0.000020\t Accuracy:100.000%\n",
      "Epoch : 211 [0/5376 (0%)]\tLoss: 0.000020\t Accuracy:100.000%\n",
      "Epoch : 212 [0/5376 (0%)]\tLoss: 0.000019\t Accuracy:100.000%\n",
      "Epoch : 213 [0/5376 (0%)]\tLoss: 0.000019\t Accuracy:100.000%\n",
      "Epoch : 214 [0/5376 (0%)]\tLoss: 0.000019\t Accuracy:100.000%\n",
      "Epoch : 215 [0/5376 (0%)]\tLoss: 0.000018\t Accuracy:100.000%\n",
      "Epoch : 216 [0/5376 (0%)]\tLoss: 0.000018\t Accuracy:100.000%\n",
      "Epoch : 217 [0/5376 (0%)]\tLoss: 0.000018\t Accuracy:100.000%\n",
      "Epoch : 218 [0/5376 (0%)]\tLoss: 0.000017\t Accuracy:100.000%\n",
      "Epoch : 219 [0/5376 (0%)]\tLoss: 0.000017\t Accuracy:100.000%\n",
      "Epoch : 220 [0/5376 (0%)]\tLoss: 0.000017\t Accuracy:100.000%\n",
      "Epoch : 221 [0/5376 (0%)]\tLoss: 0.000017\t Accuracy:100.000%\n",
      "Epoch : 222 [0/5376 (0%)]\tLoss: 0.000016\t Accuracy:100.000%\n",
      "Epoch : 223 [0/5376 (0%)]\tLoss: 0.000016\t Accuracy:100.000%\n",
      "Epoch : 224 [0/5376 (0%)]\tLoss: 0.000016\t Accuracy:100.000%\n",
      "Epoch : 225 [0/5376 (0%)]\tLoss: 0.000015\t Accuracy:100.000%\n",
      "Epoch : 226 [0/5376 (0%)]\tLoss: 0.000015\t Accuracy:100.000%\n",
      "Epoch : 227 [0/5376 (0%)]\tLoss: 0.000015\t Accuracy:100.000%\n",
      "Epoch : 228 [0/5376 (0%)]\tLoss: 0.000015\t Accuracy:100.000%\n",
      "Epoch : 229 [0/5376 (0%)]\tLoss: 0.000014\t Accuracy:100.000%\n",
      "Epoch : 230 [0/5376 (0%)]\tLoss: 0.000014\t Accuracy:100.000%\n",
      "Epoch : 231 [0/5376 (0%)]\tLoss: 0.000014\t Accuracy:100.000%\n",
      "Epoch : 232 [0/5376 (0%)]\tLoss: 0.000014\t Accuracy:100.000%\n",
      "Epoch : 233 [0/5376 (0%)]\tLoss: 0.000014\t Accuracy:100.000%\n",
      "Epoch : 234 [0/5376 (0%)]\tLoss: 0.000013\t Accuracy:100.000%\n",
      "Epoch : 235 [0/5376 (0%)]\tLoss: 0.000013\t Accuracy:100.000%\n",
      "Epoch : 236 [0/5376 (0%)]\tLoss: 0.000013\t Accuracy:100.000%\n",
      "Epoch : 237 [0/5376 (0%)]\tLoss: 0.000013\t Accuracy:100.000%\n",
      "Epoch : 238 [0/5376 (0%)]\tLoss: 0.000012\t Accuracy:100.000%\n",
      "Epoch : 239 [0/5376 (0%)]\tLoss: 0.000012\t Accuracy:100.000%\n",
      "Epoch : 240 [0/5376 (0%)]\tLoss: 0.000012\t Accuracy:100.000%\n",
      "Epoch : 241 [0/5376 (0%)]\tLoss: 0.000012\t Accuracy:100.000%\n",
      "Epoch : 242 [0/5376 (0%)]\tLoss: 0.000012\t Accuracy:100.000%\n",
      "Epoch : 243 [0/5376 (0%)]\tLoss: 0.000011\t Accuracy:100.000%\n",
      "Epoch : 244 [0/5376 (0%)]\tLoss: 0.000011\t Accuracy:100.000%\n",
      "Epoch : 245 [0/5376 (0%)]\tLoss: 0.000011\t Accuracy:100.000%\n",
      "Epoch : 246 [0/5376 (0%)]\tLoss: 0.000011\t Accuracy:100.000%\n",
      "Epoch : 247 [0/5376 (0%)]\tLoss: 0.000011\t Accuracy:100.000%\n",
      "Epoch : 248 [0/5376 (0%)]\tLoss: 0.000011\t Accuracy:100.000%\n",
      "Epoch : 249 [0/5376 (0%)]\tLoss: 0.000010\t Accuracy:100.000%\n"
     ]
    }
   ],
   "source": [
    "loss_vec = fit(mlp, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(loss_vec)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "777eb068065662bea355507597b158eb8713b7f2"
   },
   "source": [
    "## MLP Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "_uuid": "a3aca2215610465fcccc58f1b98fc1d56096f364"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:61.500% \n"
     ]
    }
   ],
   "source": [
    "def evaluate(model):\n",
    "#model = mlp\n",
    "    predict_list = []\n",
    "    correct = 0 \n",
    "    for test_imgs, test_labels in test_loader:\n",
    "        #print(test_imgs.shape)\n",
    "        test_imgs = Variable(test_imgs).float()\n",
    "        output = model(test_imgs)\n",
    "        predicted = torch.max(output,1)[1]\n",
    "        predict_list.append(predicted)\n",
    "        correct += (predicted == test_labels).sum()\n",
    "    print(\"Test accuracy:{:.3f}% \".format( float(correct)*100 / (len(test_loader)*BATCH_SIZE)))\n",
    "predict = evaluate(mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "810c7b5869b3c704d5a5a7e28289133c27c5790c"
   },
   "source": [
    "<center><h2>Convolutional Neural Network</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0dd01423ecc2b3c46c42aaa033ad8556ba029dc9"
   },
   "source": [
    "## Explanation\n",
    "\n",
    "To better understand convolutional neural network I recommend the great section on it here : http://cs231n.github.io/convolutional-networks/\n",
    "\n",
    "**Convolutional operation** : First let's clarify briefly how we can perform the convolutional operation on an image. For that we need to define a **kernel** which is a small matrix of size 5 \\* 5 for example. To perform the convolution operation, we just need to slide the kernel along the image horizontally and vertically and do the dot product of the kernel and the small portion of the image.\n",
    "\n",
    "**Pooling** : the convolutional operation give an output of the same size of the input image. To reduce the size of the image and thus reduce the number of paramers in the model we perform a Pooling operation. The pooling operation need a window size.. By sliding the window along the image, we compute the mean or the max of the portion of the image inside the window in case of MeanPooling or MaxPooling.\n",
    "\n",
    "**Stride** is the number of pixels to pass at a time when sliding the convolutional kernel.  \n",
    "\n",
    "**Padding** to preserve exactly the size of the input image, it is useful to add a zero padding on the border of the image. \n",
    "\n",
    "\n",
    "**To remember** : What makes a CNN so interesting for images is that it is invariant by translation and for each convolutional layer we only need to store the kernels. Thus we can stack a lot of layers to learn deep features without having too much parameters that would make a model untrainnable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9baaa52b6b9b6b8f8287a10fcc801606848fb726"
   },
   "source": [
    "## Data loader\n",
    "\n",
    "Since a CNN needs a image shape as input let's reshape our flatten images to real image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "_uuid": "5e84347012cd6abc2f6f46299aab08b0c89563ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5376, 1, 50, 50])\n",
      "torch.Size([1344, 1, 50, 50])\n"
     ]
    }
   ],
   "source": [
    "torch_X_train = torch_X_train.view(-1, 1,50,50).float()\n",
    "torch_X_test = torch_X_test.view(-1,1,50,50).float()\n",
    "print(torch_X_train.shape)\n",
    "print(torch_X_test.shape)\n",
    "\n",
    "# Pytorch train and test sets\n",
    "train = torch.utils.data.TensorDataset(torch_X_train,torch_y_train)\n",
    "test = torch.utils.data.TensorDataset(torch_X_test,torch_y_test)\n",
    "\n",
    "# data loader\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size = BATCH_SIZE, shuffle = False)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size = BATCH_SIZE, shuffle = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "_uuid": "c669e5f557724154d9f4f5f8b5d0d6c9b676d551"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=5184, out_features=125, bias=True)\n",
      "  (fc2): Linear(in_features=125, out_features=10, bias=True)\n",
      ")\n",
      "torch.Size([200, 1, 50, 50])\n",
      "torch.Size([200, 10])\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(32,64, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(9*9*64,125)\n",
    "        self.fc2 =nn.Linear(125,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = F.relu(F.max_pool2d(self.conv3(x),2))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = x.view(-1,9*9*64)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    " \n",
    "cnn = CNN()\n",
    "print(cnn)\n",
    "\n",
    "it = iter(train_loader)\n",
    "X_batch, y_batch = next(it)\n",
    "print(X_batch.shape)\n",
    "print(cnn.forward(X_batch).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "_uuid": "797cbe3cff05d8bdb42f3273a06839b18daf5266"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 [0/5376 (0%)]\tLoss: 2.300618\t Accuracy:11.000%\n",
      "Epoch : 1 [0/5376 (0%)]\tLoss: 2.141267\t Accuracy:24.000%\n",
      "Epoch : 2 [0/5376 (0%)]\tLoss: 1.844463\t Accuracy:37.000%\n",
      "Epoch : 3 [0/5376 (0%)]\tLoss: 1.667828\t Accuracy:45.500%\n",
      "Epoch : 4 [0/5376 (0%)]\tLoss: 1.402853\t Accuracy:53.000%\n",
      "Epoch : 5 [0/5376 (0%)]\tLoss: 1.285275\t Accuracy:56.500%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Blade\\OneDrive - University of Florida\\Coding\\CNN_Learning_2\\cnn-with-pytorch-for-mnist.ipynb Cell 25'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Blade/OneDrive%20-%20University%20of%20Florida/Coding/CNN_Learning_2/cnn-with-pytorch-for-mnist.ipynb#ch0000026?line=0'>1</a>\u001b[0m fit(cnn,train_loader)\n",
      "\u001b[1;32mc:\\Users\\Blade\\OneDrive - University of Florida\\Coding\\CNN_Learning_2\\cnn-with-pytorch-for-mnist.ipynb Cell 15'\u001b[0m in \u001b[0;36mfit\u001b[1;34m(model, train_loader)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Blade/OneDrive%20-%20University%20of%20Florida/Coding/CNN_Learning_2/cnn-with-pytorch-for-mnist.ipynb#ch0000016?line=12'>13</a>\u001b[0m output \u001b[39m=\u001b[39m model(var_X_batch)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Blade/OneDrive%20-%20University%20of%20Florida/Coding/CNN_Learning_2/cnn-with-pytorch-for-mnist.ipynb#ch0000016?line=13'>14</a>\u001b[0m loss \u001b[39m=\u001b[39m error(output, var_y_batch)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Blade/OneDrive%20-%20University%20of%20Florida/Coding/CNN_Learning_2/cnn-with-pytorch-for-mnist.ipynb#ch0000016?line=14'>15</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Blade/OneDrive%20-%20University%20of%20Florida/Coding/CNN_Learning_2/cnn-with-pytorch-for-mnist.ipynb#ch0000016?line=15'>16</a>\u001b[0m lossvec\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Blade/OneDrive%20-%20University%20of%20Florida/Coding/CNN_Learning_2/cnn-with-pytorch-for-mnist.ipynb#ch0000016?line=16'>17</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\hw\\lib\\site-packages\\torch\\_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Blade/Anaconda3/envs/hw/lib/site-packages/torch/_tensor.py?line=353'>354</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/Blade/Anaconda3/envs/hw/lib/site-packages/torch/_tensor.py?line=354'>355</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    <a href='file:///c%3A/Users/Blade/Anaconda3/envs/hw/lib/site-packages/torch/_tensor.py?line=355'>356</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    <a href='file:///c%3A/Users/Blade/Anaconda3/envs/hw/lib/site-packages/torch/_tensor.py?line=356'>357</a>\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Blade/Anaconda3/envs/hw/lib/site-packages/torch/_tensor.py?line=360'>361</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    <a href='file:///c%3A/Users/Blade/Anaconda3/envs/hw/lib/site-packages/torch/_tensor.py?line=361'>362</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> <a href='file:///c%3A/Users/Blade/Anaconda3/envs/hw/lib/site-packages/torch/_tensor.py?line=362'>363</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\hw\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Blade/Anaconda3/envs/hw/lib/site-packages/torch/autograd/__init__.py?line=167'>168</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    <a href='file:///c%3A/Users/Blade/Anaconda3/envs/hw/lib/site-packages/torch/autograd/__init__.py?line=169'>170</a>\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Blade/Anaconda3/envs/hw/lib/site-packages/torch/autograd/__init__.py?line=170'>171</a>\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Blade/Anaconda3/envs/hw/lib/site-packages/torch/autograd/__init__.py?line=171'>172</a>\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Blade/Anaconda3/envs/hw/lib/site-packages/torch/autograd/__init__.py?line=172'>173</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Blade/Anaconda3/envs/hw/lib/site-packages/torch/autograd/__init__.py?line=173'>174</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    <a href='file:///c%3A/Users/Blade/Anaconda3/envs/hw/lib/site-packages/torch/autograd/__init__.py?line=174'>175</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fit(cnn,train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "890dfc8d29ac70df919807b275b38112ca9297ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:10.071% \n"
     ]
    }
   ],
   "source": [
    "evaluate(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.2556, -2.3080, -2.3297,  ..., -2.3225, -2.3270, -2.3085],\n",
      "        [-2.2557, -2.3084, -2.3296,  ..., -2.3227, -2.3274, -2.3082],\n",
      "        [-2.2759, -2.3518, -2.3248,  ..., -2.3471, -2.3643, -2.2778],\n",
      "        ...,\n",
      "        [-2.2575, -2.3123, -2.3292,  ..., -2.3249, -2.3307, -2.3055],\n",
      "        [-2.2759, -2.3518, -2.3248,  ..., -2.3471, -2.3643, -2.2778],\n",
      "        [-2.2759, -2.3518, -2.3248,  ..., -2.3471, -2.3643, -2.2778]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "torch.Size([200, 1, 300, 300])\n",
      "torch.Size([200, 10])\n",
      "torch.Size([200])\n",
      "tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 0, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 0, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 0, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 0, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6])\n"
     ]
    }
   ],
   "source": [
    "output = cnn.forward(X_batch)\n",
    "predicted = torch.max(output.data,1)[1]\n",
    "print(output)\n",
    "print(X_batch.shape)\n",
    "print(output.shape)\n",
    "print(predicted.shape)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 0, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 0, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 0, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 0, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6])\n"
     ]
    }
   ],
   "source": [
    "predicted = torch.max(output.data,1)[1]\n",
    "print(predicted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
